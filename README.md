<h1 align="center">
  <br>
  <img src=https://user-images.githubusercontent.com/54723897/113879941-4e1af480-97bb-11eb-83f3-e0ec8772b7c4.gif width=500px>
  <br>    
</h1>

<h2 align="center">CloudSEN12 a global benchmark dataset for cloud semantic understanding</h2>

<p align="center">  
  • 
  <a href="#why-we-need-another-cloud-detection-dataset">Why we need another cloud detection dataset?</a> &nbsp;•  
  <a href="#metodology">Metodology</a> &nbsp;•
  <a href="#citation">Citation</a> &nbsp;•
  <a href="#credits">Credits</a>  
</p>

## Why we need another cloud detection dataset?

In the last years, we have witnessed the success of deep learning in semantic segmentation thanks to the availability of large-scale human-annotated datasets such as [**Cityscapes**](https://www.cityscapes-dataset.com/). However, in earth observation, more concretely in **cloud detection**, this revolution and remarkable gain in model efficiency have not happened yet.  Although many factors may be related to this, dataset availability is by far the central dilemma. To the best of our knowledge, current cloud detection datasets have some of these shortcomings:

- Regional spatial coverage.
- Lack of annotation richness.
- Insufficient metadata.
- Poor hand-crafted labeling.
- Lack of variety.
- Only designed to support standard supervised learning.
- Absence of a criteria of what we should to considerate as a cloud.

## cloudSEN12 characteristics
	
- Provide 20 features, including SAR and multispectral data.
- Fifty thousand globally distributed image patches (511 x 511).
- Three different types of manual labeling: high-quality labels, scrabble labeling, and no labeling.
- Each image has the result of seven state-of-the-art cloud detection algorithm.
- Supports standard supervised learning and generalizations like weakly supervision, semi-supervised learning, few-shot learning, and novel approaches based on SAR-to-Optical image fusion.
- Freely available with love <3 using the STAC specification.
- 50 000 image patches (511 x 511) globally distributed.


## Metodology

<center>
  <br>
    <img src=https://user-images.githubusercontent.com/54723897/113933190-90145c80-97f4-11eb-8b52-584826d67cf3.png>
  <br>    
</center>

## Citation 

	COMMING SOON 
	
## Credits

	COMMING SOON 
