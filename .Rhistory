# 9.4 Create a plot and download
crs(final_stack) <- st_crs(img_crs)$proj4string
png(sprintf("%s/%s.png", dir_id, img_id), 1000, 1000)
max_value <- max(maxValue(final_stack))
plotRGB(final_stack/max_value, r = 3, g = 2, b = 1, scale = 1)
dev.off()
}
# 10. Create the metadata.json file
metadata_dataset_creator(
cloudsen2_row = cloudsen2_row,
output = output
)
}
select_dataset_thumbnail_creator(cloudsen2_row = cloudsen2_row,n_images = 1)
cloudsen2_row <- local_cloudsen2_points[index,]
n_images = 1
cloudsen2_row = cloudsen2_row
cloudsen2_row
kernel_size = c(255, 255)
data_range = c("2019-01-01", "2020-07-31")
output = "results/"
# 1. Create output directory
dir.create(output, showWarnings = FALSE)
# 2. Create a point which represent the center of the chip (from local to ee)
point <- ee$Geometry$Point(cloudsen2_row$geometry[[1]])
# 3. Create a S2 ImageCollection.
s2Sr <- ee$ImageCollection("COPERNICUS/S2_SR") %>%
ee$ImageCollection$filterBounds(point) %>%
ee$ImageCollection$filterDate(data_range[1], data_range[2])
# 4. Create a S1 ImageCollection.
data_range2 <- c(as.Date(data_range[1]) - 5, as.Date(data_range[2]) + 5) %>% as.character()
s1_grd <- ee$ImageCollection("COPERNICUS/S1_GRD") %>%
ee$ImageCollection$filterBounds(point) %>%
ee$ImageCollection$filterDate(data_range2[1], data_range2[2]) %>%
# Filter to get images with VV and VH dual polarization.
ee$ImageCollection$filter(ee$Filter$listContains("transmitterReceiverPolarisation", "VV")) %>%
ee$ImageCollection$filter(ee$Filter$listContains('transmitterReceiverPolarisation', "VH")) %>%
# Filter to get images collected in interferometric wide swath mode.
ee$ImageCollection$filter(ee$Filter$eq("instrumentMode", "IW"))
# 5. Get dates from all the images which are part of S1 and S2 ImageCollection.
s2_dates <- ee_get_date_ic(s2Sr) %>% as_tibble()
s1_dates <- ee_get_date_ic(s1_grd) %>% as_tibble()
sx_fx <- function(x) min(abs(s2_dates$time_start[x] - s1_dates$time_start))
mindays <- sapply(seq_len(nrow(s2_dates)), sx_fx)
valid_s2 <- s2_dates[mindays < 2.5,] # Pick up images with no more than 2.5 days of delay
# Display the number of available images with an S2/S1 pair
message(sprintf("Number of images: %s", nrow(valid_s2)))
# 6. Get the CRS of this specific point (5 images)
img_crs <- s2Sr$first()$select(0)$projection()$getInfo()[["crs"]]
# 7. shuffle valid images
images_position <- sample(nrow(valid_s2), nrow(valid_s2))
if (length(images_position) < 50) {
warning("Insufficient number of images ... PLEASE REPORT!")
}
images_position
if (length(images_position) < 50) {
warning("Insufficient number of images ... PLEASE REPORT!")
}
# 8. Create a folder to save results
dir_id <- sprintf("%s/point_%04d",output, cloudsen2_row$id)
dir.create(dir_id, showWarnings = FALSE)
# 9. Download all the image thumbnails
counter <- 0
images_position
n_images
valid_s2
nrow(valid_s2)
nrow(valid_s2)
n_images
nrow(valid_s2)
for (r_index in images_position) {
if (counter == n_images) {
break
}
# 9.1 Select the image
img_to_download <- ee$Image(valid_s2$id[r_index])
img_id <- basename(valid_s2$id[r_index])
# 9.2 Download the S2 thumbnail image (as a json)
s2_img_array <- img_to_download %>%
ee$Image$select(c("B4", "B3", "B2")) %>%
ee$Image$addBands(ee$Image$pixelCoordinates(projection = img_crs)) %>%
# ee$Image$reproject(crs = img_crs, scale = 10) %>%
ee$Image$neighborhoodToArray(
kernel = ee$Kernel$rectangle(kernel_size[1], kernel_size[2], "pixels")
) %>%
ee$Image$sampleRegions(ee$FeatureCollection(point),
projection = img_crs,
scale = 10) %>%
ee$FeatureCollection$getInfo()
# Some image have FULL NA values if that occurs skip
band_names <- try(
expr = names(s2_img_array$features[[1]]$properties),
silent = TRUE
)
if (class(band_names) == "try-error") {
next
}
message(
sprintf("Processing point [%s] image [%s] ... please wait",
cloudsen2_row$id, counter)
)
# 9.3 From list to data_frame
extract_fn <- function(x) as.numeric(unlist(s2_img_array$features[[1]]$properties[x]))
image_as_df <- do.call(cbind,lapply(band_names, extract_fn))
colnames(image_as_df) <- band_names
image_as_tibble <- as_tibble(image_as_df)
# If all values in the image are zero, skip
if (sum(image_as_tibble[["B2"]] == 0) > 0) {
next
} else {
counter <- counter + 1
}
# 9.4 From data_frame to sp; From sp to raster
coordinates(image_as_tibble) <- ~x+y
sf_to_stack <- function(x) rasterFromXYZ(image_as_tibble[x])
final_stack <- stack(lapply(names(image_as_tibble), sf_to_stack))
# 9.4 Create a plot and download
crs(final_stack) <- st_crs(img_crs)$proj4string
png(sprintf("%s/%s.png", dir_id, img_id), 1000, 1000)
max_value <- max(maxValue(final_stack))
plotRGB(final_stack/max_value, r = 3, g = 2, b = 1, scale = 1)
dev.off()
}
cloudsen2_row
output
# 10. Create the metadata.json file
metadata_dataset_creator(
cloudsen2_row = cloudsen2_row,
output = output
)
cloudsen2_row = cloudsen2_row
output = output
dir_name_point <- sprintf("%s/point_%04d/", output, cloudsen2_row$id)
dir_name_point
json_file <- sprintf("%s/cprob_%04d.json", dir_name_point, cloudsen2_row$id)
json_file
cprob <- jsonlite::read_json(json_file)
json_file
cprob <- jsonlite::read_json(json_file)
json_file
cloudsen2_row
output
dir_name_point <- sprintf("%s/point_%04d/", output, cloudsen2_row$id)
json_file <- sprintf("%s/cprob_%04d.json", dir_name_point, cloudsen2_row$id)
cprob <- jsonlite::read_json(json_file)
cloudsen2_row
cloudsen2_row = cloudsen2_row
output = output
dir_name_point <- sprintf("%s/point_%04d/", output, cloudsen2_row$id)
dir_name_point
cloudsen2_row
cloudsen2_row
dir_name_point <- sprintf("%s/point_%04d/", output, cloudsen2_row$id)
dir_name_point
cloudsen2_row
cloudsen2_row[3:6]
cloudsen2_row[3:8]
names(cloudsen2_row[3:8])
cloudsen2_row[3:8]
names(cloudsen2_row[4:8])
cprob_n <-names(cloudsen2_row[4:8])[-6]
cprob_n
cloudsen2_row[4:8]
cprob_n <- names(cloudsen2_row[4:8][-6])
cprob_n
cloudsen2_row
cloudsen2_row_no_sf <- st_drop_geometry(cloudsen2_row)
cloudsen2_row_no_sf
cprob_n <- names(cloudsen2_row_no_sf[4:8])
cprob_n
pprob_v <- as.numeric(cloudsen2_row_no_sf[4:8])
pprob_v
cprob_n <- names(cloudsen2_row_no_sf[4:8])
pprob_v <- as.numeric(cloudsen2_row_no_sf[4:8])
row_id <- gsub("cprob_|\\.json$", "", basename(json_file)) %>% as.numeric()
row_id
json_file
basename(json_file)
cloudsen2_row
row_id <- cloudsen2_row$id
row_id
row_id <- cloudsen2_row$id
local_cloudsen2_points
local_cloudsen2_points[row_id,]
row_id <- cloudsen2_row$id
metadata_point <- local_cloudsen2_points[row_id,]
coord_xy <- as.numeric(metadata_point$geometry[[1]])
coord_xy
param_id <- list()
param_id
for (index in seq_along(cprob_n)) {
param_id[[index]] <- list(
cloud_type = NA,
cloud_height = NA,
cloud_thickness = NA,
potential_cloud_coverage = pprob_v[index]
)
}
names(param_id) <- cprob_n
param_id$surface_type <- as.character(metadata_point$type)
param_id$x <- coord_xy[1]
param_id$y <- coord_xy[2]
param_id$comments <- cprob$comments
cprob
param_id
param_id
param_id$y <- coord_xy[2]
param_id$comments <- "PUT_HERE_YOUR_COMMENT"
param_id
param_id
sprintf("%s/metadata_%04d.json", dir_name_point, cloudsen2_row$id)
jsonlite::write_json(
x = param_id,
path = sprintf("%s/metadata_%04d.json", dir_name_point, cloudsen2_row$id),
pretty = TRUE,
auto_unbox = TRUE
)
metadata_dataset_creator <- function(cloudsen2_row,
output = "results/") {
dir_name_point <- sprintf("%s/point_%04d/", output, cloudsen2_row$id)
cloudsen2_row_no_sf <- st_drop_geometry(cloudsen2_row)
cprob_n <- names(cloudsen2_row_no_sf[4:8])
pprob_v <- as.numeric(cloudsen2_row_no_sf[4:8])
row_id <- cloudsen2_row$id
metadata_point <- local_cloudsen2_points[row_id,]
coord_xy <- as.numeric(metadata_point$geometry[[1]])
param_id <- list()
for (index in seq_along(cprob_n)) {
param_id[[index]] <- list(
cloud_type = NA,
cloud_height = NA,
cloud_thickness = NA,
potential_cloud_coverage = pprob_v[index]
)
}
names(param_id) <- cprob_n
param_id$surface_type <- as.character(metadata_point$type)
param_id$x <- coord_xy[1]
param_id$y <- coord_xy[2]
param_id$comments <- "PUT_HERE_YOUR_COMMENT"
jsonlite::write_json(
x = param_id,
path = sprintf("%s/metadata_%04d.json", dir_name_point, cloudsen2_row$id),
pretty = TRUE,
auto_unbox = TRUE
)
}
index <- 1451
cloudsen2_row <- local_cloudsen2_points[index,]
cloudsen2_row
select_dataset_thumbnail_creator(cloudsen2_row = cloudsen2_row)
select_dataset_thumbnail_creator(cloudsen2_row = cloudsen2_row,n_images = 2)
View(cloudsen2_row)
# 5. List all the metadata
all_files <- drive_ls(as_id("1fBGAjZkjPEpPr0p7c-LtJmfbLq3s87RK"))
# 1. Libraries
library(googleCloudStorageR)
library(googledrive)
library(tidyverse)
library(jsonlite)
library(mapview)
library(mapedit)
library(raster)
library(scales)
library(stars)
library(purrr)
library(grid)
library(rgee)
library(png)
library(sf)
library(sp)
source("src/utils.R")
# 2. Initialize Earth Engine
ee_Initialize("aybar1994", drive = TRUE, gcs = TRUE)
# 5. List all the metadata
all_files <- drive_ls(as_id("1fBGAjZkjPEpPr0p7c-LtJmfbLq3s87RK"))
all_files
jsonfile <- all_files
jsonfile <- all_files[1]
jsonfile
all_files
all_files[1]
all_files
jsonfile <- all_files[1,]
jsonfile
jsonfile <-
drive_download(all_files[1,])
# 5. List all the metadata
all_files <- drive_ls(as_id("1fBGAjZkjPEpPr0p7c-LtJmfbLq3s87RK"))
# 1. Libraries
library(googleCloudStorageR)
library(googledrive)
library(tidyverse)
library(jsonlite)
library(mapview)
library(mapedit)
library(raster)
library(scales)
library(stars)
library(purrr)
library(grid)
library(rgee)
library(png)
library(sf)
library(sp)
source("src/utils.R")
# 2. Initialize Earth Engine
ee_Initialize("aybar1994", drive = TRUE, gcs = TRUE)
# 3. Load points with desired cloud average (after run point_creator.R)
local_cloudsen2_points <- read_sf("data/cloudsen2_potential_points.geojson")
# 5. List all the metadata
jsonfile <- search_metajson(pattern = "metadata_0003.json", clean = FALSE)
pattern = "metadata_0003.json"
clean
clean = FALSE
drive <- sprintf("%s/drive_dataset.Rdata", tempdir())
if (clean) {
suppressWarnings(file.remove(drive))
}
if (!file.exists(drive)) {
# 5. List all the metadata
drive_jsonfile <- drive_ls(
path = as_id("1fBGAjZkjPEpPr0p7c-LtJmfbLq3s87RK")
)
save(drive_jsonfile, file = drive)
} else {
load(drive)
}
drive_jsonfile_s <- drive_jsonfile[drive_jsonfile$name %in% pattern, ]
drive_jsonfile_s
# 5. List all the metadata
jsonfile <- search_metajson(pattern = "metadata_0004.json", clean = FALSE)
jsonfile
# 5. List all the metadata
jsonfile <- search_metajson(pattern = "metadata_0004.json", clean = FALSE)
jsonfile
# 6. Download all images in IRIS format :)
dataset_creator_chips(
jsonfile = jsonfile,
output_final = "/home/csaybar/Desktop/cloudsen12"
)
jsonfile = jsonfile
output_final = "/home/csaybar/Desktop/cloudsen12"
kernel_size = c(255, 255)
output_final = "cloudsen12/"
point_name <- paste0("point_", gsub("[a-zA-Z]|_|\\.","", basename(jsonfile)))
# 1. Read JSON file
jsonfile_r <- jsonlite::read_json(jsonfile)
# 2. Identify all the S2 images
s2_ids <- sprintf("COPERNICUS/S2/%s", names(jsonfile_r)[1:5])
# 3. Create a st_point which represent the center of the chip
st_point <- st_sfc(geometry = st_point(c(jsonfile_r$x, jsonfile_r$y)), crs = 4326)
crs_kernel <- ee$Image(s2_ids[1])$select(0)$projection()$getInfo()$crs
point_utm <- st_transform(st_point, crs_kernel)
ee_point <- ee$Geometry$Point(point_utm[[1]], proj = crs_kernel)
ee_point
point_utm
crs_kernel
s2_ids
s2_id <- s2_ids[1]
message(sprintf("Downloading: %s", s2_id))
# 3.1 S2 ID and dates
s2_img <- ee$Image(s2_id)
s2_date <- ee_get_date_img(s2_img)[["time_start"]]
# 3.2 S1 ID
s1_id <- ee_get_s1(point = ee_point, s2_date = s2_date)
s1_img <- ee$Image(s1_id)
# 3.3 Create an Image collection with S2, S1 and cloud mask information
s2_fullinfo <- ee_merge_s2_full(s2_id, s1_id, s2_date)
# 3.4 Create a 511x511 tile (list -> data_frame -> sp -> raster)
band_names <- c(s2_fullinfo$bandNames()$getInfo(), "x", "y")
s2_img_array <- s2_fullinfo$addBands(s1_img) %>%
ee$Image$addBands(ee$Image$pixelCoordinates(projection = crs_kernel)) %>%
ee$Image$neighborhoodToArray(
kernel = ee$Kernel$rectangle(kernel_size[1], kernel_size[2], "pixels")
) %>%
ee$Image$sampleRegions(ee$FeatureCollection(ee_point),
projection = crs_kernel,
scale = 10) %>%
ee$FeatureCollection$getInfo()
extract_fn <- function(x) as.numeric(unlist(s2_img_array$features[[1]]$properties[x]))
image_as_df <- do.call(cbind,lapply(band_names, extract_fn))
colnames(image_as_df) <- band_names
image_as_tibble <- as_tibble(image_as_df)
coordinates(image_as_tibble) <- ~x+y
sf_to_stack <- function(x) rasterFromXYZ(image_as_tibble[x])
final_stack <- stack(lapply(names(image_as_tibble), sf_to_stack))
crs(final_stack) <- st_crs(crs_kernel)$proj4string
final_stack
s2_ids[[1]]
final_stack
final_stack
# 4 Save geometry
final_stack[[1]]
# 4 Save geometry
final_stack[[1]]*1
# 4 Save geometry
plot(final_stack)
# 4 Save geometry
plot(final_stack[[1]]*0+1)
final_stack[[1]]*0+1
# 4 Save geometry
rasterToPolygons(final_stack[[1]]*0+1)
# 4 Save geometry
rasterToPolygons(final_stack[[1]]*0+1, dissolve=TRUE)
st_buffer(point_utm, endCapStyle = "SQUARE")
st_buffer(point_utm, 10*255, endCapStyle = "SQUARE")
st_buffer(point_utm, (10*255)/2, endCapStyle = "SQUARE")
point_utm
st_buffer(point_utm, (10*255)/2, endCapStyle = "SQUARE")
point_utm
(10*255)/2
basename(s2_id)
raster()
endCapStyle
input_data
final_stack
plot(final_stack)
plot(final_stack[[1]])
final_stack[[1]]
final_stack[[1]]
extent(final_stack[[1]])
extent(final_stack[[1]]) %>% st_as_sf()
extent(final_stack[[1]]) %>% st_bbox()
extent(final_stack[[1]]) %>% st_bbox() %>% st_as_sfc()
extent(final_stack[[1]]) %>%
st_bbox()
extent(final_stack[[1]]) %>%
st_bbox() %>%
st_as_sfc()
roi <- extent(final_stack[[1]]) %>%
st_bbox() %>%
st_as_sfc()
roi
final_stack[[1]]
crs_kernel
crs_kernel
st_transform(roi) <- crs_kernel
roi
roi <- extent(final_stack[[1]]) %>%
st_bbox() %>%
st_as_sfc()
st_transform(roi) <- crs_kernel
st_crs(roi) <- crs_kernel
roi
roi
crs_kernel
final_stack[[1]]
plot(final_stack[[1]])
plot(roi, add = TRUE)
plot(final_stack[[1]])
plot(roi, add = TRUE)
roi
output_final_folder
# 3.5 Prepare folders for iris
output_final_d <- sprintf("%s/dataset", output_final)
output_final_folder <- sprintf("%s/dataset/%s/%s", output_final, point_name, basename(s2_id))
metadata_main <- sprintf("%s/cloud_segmentation_%s.json", output_final, point_name)
metadata_spec <- sprintf("%s/dataset/%s/%s/metadata.json", output_final, point_name, basename(s2_id))
output_final_folder
basename(output_final_folder)
dirname(output_final_folder)
dirname(output_final_folder)
dirname(output_final_folder)
sprintf("%s/", dirname(output_final_folder))
output_final_folder
point_name
point_name
sprintf("%s/cloudsen12_%s.", dirname(output_final_folder), point_name)
sprintf("%s/cloudsen12_%s.gpkg", dirname(output_final_folder), point_name)
sprintf("%s/cloudsen12_%s.gpkg", dirname(output_final_folder), point_name)
write_sf(roi, sprintf("%s/cloudsen12_%s.gpkg", dirname(output_final_folder), point_name))
sprintf("%s/cloudsen12_%s.gpkg", dirname(output_final_folder), point_name)
write_sf(roi, sprintf("%s/%s.gpkg", dirname(output_final_folder), point_name))
write_sf(roi, sprintf("%s/%s.TopoJSON", dirname(output_final_folder), point_name))
write_sf(roi, sprintf("%s/%s.json", dirname(output_final_folder), point_name))
write_sf(roi, sprintf("%s/%s.topojson", dirname(output_final_folder), point_name))
write_sf(roi, sprintf("%s/%s.geojson", dirname(output_final_folder), point_name))
write_sf(roi, sprintf("%s/cloudsen12_%s.gpkg", dirname(output_final_folder), point_name))
sprintf("%s/cloudsen12_%s.gpkg", dirname(output_final_folder), point_name)
write_sf(roi, sprintf("%s/cloudsen12_%s.shp", dirname(output_final_folder), point_name))
sprintf("%s/%s.gpkg", dirname(output_final_folder), point_name)
setwd("/home/csaybar/Desktop/cloudsen12/dataset/point_0004/")
write_sf(roi, sprintf("%s/%s.gpkg", dirname(output_final_folder), point_name))
sprintf("%s/%s.gpkg", dirname(output_final_folder), point_name)
setwd("/home/csaybar/Desktop/")
write_sf(roi, sprintf("%s/%s.gpkg", dirname(output_final_folder), point_name))
# 5. List all the metadata
jsonfile <- search_metajson(pattern = "metadata_0004.json", clean = FALSE)
# 1. Libraries
library(googleCloudStorageR)
library(googledrive)
library(tidyverse)
library(jsonlite)
library(mapview)
library(mapedit)
library(raster)
library(scales)
library(stars)
library(purrr)
library(grid)
library(rgee)
library(png)
library(sf)
library(sp)
source("src/utils.R")
# 2. Initialize Earth Engine
ee_Initialize("aybar1994", drive = TRUE, gcs = TRUE)
# 3. Load points with desired cloud average (after run point_creator.R)
local_cloudsen2_points <- read_sf("data/cloudsen2_potential_points.geojson")
# 3. Load points with desired cloud average (after run point_creator.R)
local_cloudsen2_points <- read_sf("data/cloudsen2_potential_points.geojson")
