ndmi <- img$normalizedDifference(c("B8", "B11"))
score <- score$min(rescale(ndmi, "img", c(-0.1, 0.1)))
# However, clouds are not snow.
ndsi <- img$normalizedDifference(c("B3", "B11"))
score <- score$min(rescale(ndsi, 'img', c(0.8, 0.6)))
# Clip the lower end of the score
score <- score$max(ee$Image(0.001))
# Remove small regions and clip the upper bound
dilated <- dilatedErossion(score)$min(ee$Image(1.0))
# score = score.multiply(dilated)
score <- score$reduceNeighborhood(
reducer = ee$Reducer$mean(),
kernel = ee$Kernel$square(5)
)
img$addBands(score$rename("cloudScore"))
}
# Reclass cloudsen12
probability_to_binary <- function(img) {
boxcar1 <- ee$Kernel$square(radius = 4, units = 'pixels')
boxcar2 <- ee$Kernel$square(radius = 2, units = 'pixels')
img %>%
ee$Image$convolve(boxcar1) %>%
ee$Image$focal_max(kernel = boxcar2, iterations = 1) %>%
ee$Image$gte(0.4)
}
# ee_ipl_uv
ee_upl_cloud_logical <- function(sen2id, roi) {
image_collection_name <- 'COPERNICUS/S2/'
image_wrap <- ee_cloud$image_wrapper$S2L1CImage(
collection = image_collection_name,
index = sen2id
)
cloud_img_cc <- ee_cloud$multitemporal_cloud_masking$CloudClusterScore(
img = image_wrap,
region_of_interest = roi,
method_pred="persistence",
params = list(threshold_cc = threshold_cc)
)[[1]]
ee_results_cloud <- try(cloud_img_cc$getInfo())
# while (class(ee_results_cloud) == "try-error") {
#   threshold_cc = threshold_cc + 10
#   cloud_img_cc <- ee_cloud$multitemporal_cloud_masking$CloudClusterScore(
#     img = image_wrap,
#     region_of_interest = roi,
#     method_pred="persistence",
#     params = list(threshold_cc = threshold_cc)
#   )[[1]]
#   ee_results_cloud <- try(cloud_img_cc$getInfo())
#   if (threshold_cc == 100) {
#     stop("sorry there is no images :'(")
#   }
# }
if (class(ee_results_cloud) == "try-error") {
FALSE
} else {
TRUE
}
}
ee_upl_cloud <- function(sen2id, roi) {
image_collection_name <- 'COPERNICUS/S2/'
image_wrap <- ee_cloud$image_wrapper$S2L1CImage(
collection = image_collection_name,
index = sen2id
)
cloud_img_cc <- ee_cloud$multitemporal_cloud_masking$CloudClusterScore(
img = image_wrap,
region_of_interest = roi,
method_pred="persistence",
params = list(threshold_cc = threshold_cc)
)[[1]]
cloud_img_cc
}
shadow_direction <- function(image) {
meanAzimuth <- image$get("MEAN_SOLAR_AZIMUTH_ANGLE")
meanZenith <- image$get("MEAN_SOLAR_ZENITH_ANGLE")
azR <- ee$Number(meanAzimuth)$add(180)$multiply(base::pi)$divide(180.0)
zenR <- ee$Number(meanZenith)$multiply(base::pi)$divide(180.0)
shadowCastedDistance <- zenR$tan()
x <- azR$sin()$multiply(shadowCastedDistance)
y <- azR$cos()$multiply(shadowCastedDistance)
ee$Number$atan2(x, y)$multiply(180)$divide(base::pi) %>%
ee$Image() %>%
ee$Image$rename("cloudshadow_direction")
}
set.seed(100)
jsonfiles <- drive_jsonfile$name[sample(length(drive_jsonfile$name), 20)]
jsonfiles
for (jsonfile in jsonfiles) {
jsonfile_f <- search_metajson(pattern = jsonfile, clean = FALSE)
dataset_creator_chips(
jsonfile = jsonfile_f,
output_final = "/home/csaybar/Desktop/cloudsen12"
)
}
jsonfile
dataset_creator_chips(
jsonfile = jsonfile_f,
output_final = "/home/csaybar/Desktop/cloudsen12"
)
jsonfile = jsonfile_f
output_final = "/home/csaybar/Desktop/cloudsen12"
point_name <- paste0("point_", gsub("[a-zA-Z]|_|\\.","", basename(jsonfile)))
# 1. Read JSON file
jsonfile_r <- jsonlite::read_json(jsonfile)
# 2. Identify all the S2 images
s2_idsposition <- which(sapply(strsplit(names(jsonfile_r), "_"), length) == 3)
s2_ids <- sprintf("COPERNICUS/S2/%s", names(jsonfile_r)[s2_idsposition])
# 3. Create a st_point representing the center of the tile (255x255)
st_point <- st_sfc(geometry = st_point(c(jsonfile_r$x, jsonfile_r$y)), crs = 4326)
crs_kernel <- ee$Image(s2_ids[1])$select(0)$projection()$getInfo()$crs
point_utm <- st_transform(st_point, crs_kernel)
ee_point <- ee$Geometry$Point(point_utm[[1]], proj = crs_kernel)
# 4. Download each image for the specified point
for (s2_id in s2_ids) {
message(sprintf("Downloading: %s", s2_id))
# 4.1 S2 ID and dates
s2_img <- ee$Image(s2_id)
s2_date <- ee_get_date_img(s2_img)[["time_start"]]
# 4.2 S1 ID
s1_id <- ee_get_s1(point = ee_point, s2_date = s2_date)
s1_img <- ee$Image(s1_id)
# 4.3 Create an Image collection with S2, S1 and cloud mask information
s2_s1_img <- ee_merge_s2_full(s2_id, s1_id, s2_date)
# 4.4 ipl_uv algorithm
IPL_multitemporal_cloud_logical <- ee_upl_cloud_logical(
sen2id = basename(s2_id),
roi =  s2_img$geometry()
)
if (IPL_multitemporal_cloud_logical) {
IPL_multitemporal_cloud <- ee_upl_cloud(
sen2id = basename(s2_id),
roi =  s2_img$geometry()
)
s2_s1_img <- s2_s1_img %>%
ee$Image$addBands(IPL_multitemporal_cloud) %>%
ee$Image$unmask(-999)
}
# 4.5 Add IPL algorithm and shadow direction
s2_fullinfo <- s2_s1_img %>%
ee$Image$addBands(shadow_direction(image = s2_img))
# 4.6 Create a 511x511 tile (list -> data_frame -> sp -> raster)
band_names <- c(s2_fullinfo$bandNames()$getInfo(), "x", "y")
s2_img_array <- s2_fullinfo$addBands(s1_img) %>%
ee$Image$addBands(ee$Image$pixelCoordinates(projection = crs_kernel)) %>%
ee$Image$neighborhoodToArray(
kernel = ee$Kernel$rectangle(kernel_size[1], kernel_size[2], "pixels")
) %>%
ee$Image$sampleRegions(ee$FeatureCollection(ee_point),
projection = crs_kernel,
scale = 10) %>%
ee$FeatureCollection$getInfo()
extract_fn <- function(x) as.numeric(unlist(s2_img_array$features[[1]]$properties[x]))
image_as_df <- do.call(cbind,lapply(band_names, extract_fn))
colnames(image_as_df) <- band_names
image_as_tibble <- as_tibble(image_as_df)
coordinates(image_as_tibble) <- ~x+y
sf_to_stack <- function(x) rasterFromXYZ(image_as_tibble[x])
final_stack <- stack(lapply(names(image_as_tibble), sf_to_stack))
crs(final_stack) <- st_crs(crs_kernel)$proj4string
# 4.7 Prepare folders for iris
output_final_d <- sprintf("%s/dataset", output_final)
output_final_folder <- sprintf("%s/dataset/%s/%s", output_final, point_name, basename(s2_id))
metadata_main <- sprintf("%s/cloud_segmentation_%s.json", output_final, point_name)
metadata_spec <- sprintf("%s/dataset/%s/%s/metadata.json", output_final, point_name, basename(s2_id))
dir.create(sprintf("%s/input", output_final_folder), showWarnings = FALSE, recursive = TRUE)
dir.create(sprintf("%s/target", output_final_folder), showWarnings = FALSE, recursive = TRUE)
dir.create(sprintf("%s/thumbnails", output_final_folder), showWarnings = FALSE, recursive = TRUE)
# 4.8 Save all features inside the input folder
bandnames <- c(paste0("B",1:8), "B8A", paste0("B", 9:12), "CDI", "VV", "VH", "angle", "elevation", "landuse", "cloudshadow_direction")
input_data <- raster::stack(
final_stack[[1:13]]/10000, final_stack[[14]], final_stack[[15:17]], final_stack[[22:23]], final_stack[[25]]
)
input_spec <- sprintf("%s/input/%s.tif", output_final_folder, bandnames)
lapply(1:20, function(x) writeRaster(input_data[[x]], input_spec[x], overwrite = TRUE))
# 4.9 Save all cloud mask inside the target folder
# 18-19 -> cmask_s2cloudness| cmask_s2cloudness_reclass (0,1)
# 20-21 -> cmask_sen2cor | cmask_sen2cor_reclass (0,1,2)
# 25 -> IPL_cloudmask_reclass
bandnames <- c("s2cloudness_prob", "s2cloudness_reclass", "sen2cor_real",
"sen2cor_reclass", "IPL_cloudmask_reclass")
IPL_cloudmask_reclass <- final_stack[[24]]
# 4.10 Save cloud labels
benchmarch_data <- stack(final_stack[[c(18:21)]], IPL_cloudmask_reclass)
target_spec <- sprintf("%s/target/%s.tif", output_final_folder, bandnames)
lapply(1:5, function(x) writeRaster(benchmarch_data[[x]], target_spec[x], overwrite = TRUE))
# 4.11 Create cloud-segmentation.json (main file in iris software)
ee_create_cloudseg(path = metadata_main)
# 4.12 Create metadata.json for each file
ee_create_metadata(
id = basename(s2_id),
point = c(jsonfile_r$y, jsonfile_r$x),
path = metadata_spec
)
}
s2_id
message(sprintf("Downloading: %s", s2_id))
# 4.1 S2 ID and dates
s2_img <- ee$Image(s2_id)
s2_date <- ee_get_date_img(s2_img)[["time_start"]]
s1_img <- ee$Image(s1_id)
# 4.2 S1 ID
s1_id <- ee_get_s1(point = ee_point, s2_date = s2_date)
# 4.4 ipl_uv algorithm
IPL_multitemporal_cloud_logical <- ee_upl_cloud_logical(
sen2id = basename(s2_id),
roi =  s2_img$geometry()
)
# 4.3 Create an Image collection with S2, S1 and cloud mask information
s2_s1_img <- ee_merge_s2_full(s2_id, s1_id, s2_date)
if (IPL_multitemporal_cloud_logical) {
IPL_multitemporal_cloud <- ee_upl_cloud(
sen2id = basename(s2_id),
roi =  s2_img$geometry()
)
s2_s1_img <- s2_s1_img %>%
ee$Image$addBands(IPL_multitemporal_cloud) %>%
ee$Image$unmask(-999)
}
# 4.5 Add IPL algorithm and shadow direction
s2_fullinfo <- s2_s1_img %>%
ee$Image$addBands(shadow_direction(image = s2_img))
# 4.6 Create a 511x511 tile (list -> data_frame -> sp -> raster)
band_names <- c(s2_fullinfo$bandNames()$getInfo(), "x", "y")
band_names
s2_img_array <- s2_fullinfo$addBands(s1_img) %>%
ee$Image$addBands(ee$Image$pixelCoordinates(projection = crs_kernel)) %>%
ee$Image$neighborhoodToArray(
kernel = ee$Kernel$rectangle(kernel_size[1], kernel_size[2], "pixels")
) %>%
ee$Image$sampleRegions(ee$FeatureCollection(ee_point),
projection = crs_kernel,
scale = 10) %>%
ee$FeatureCollection$getInfo()
extract_fn <- function(x) as.numeric(unlist(s2_img_array$features[[1]]$properties[x]))
image_as_df <- do.call(cbind,lapply(band_names, extract_fn))
colnames(image_as_df) <- band_names
image_as_tibble <- as_tibble(image_as_df)
coordinates(image_as_tibble) <- ~x+y
sf_to_stack <- function(x) rasterFromXYZ(image_as_tibble[x])
final_stack <- stack(lapply(names(image_as_tibble), sf_to_stack))
crs(final_stack) <- st_crs(crs_kernel)$proj4string
crs(final_stack) <- st_crs(crs_kernel)$proj4string
# 4.7 Prepare folders for iris
output_final_d <- sprintf("%s/dataset", output_final)
output_final_folder <- sprintf("%s/dataset/%s/%s", output_final, point_name, basename(s2_id))
metadata_main <- sprintf("%s/cloud_segmentation_%s.json", output_final, point_name)
metadata_spec <- sprintf("%s/dataset/%s/%s/metadata.json", output_final, point_name, basename(s2_id))
dir.create(sprintf("%s/input", output_final_folder), showWarnings = FALSE, recursive = TRUE)
dir.create(sprintf("%s/target", output_final_folder), showWarnings = FALSE, recursive = TRUE)
dir.create(sprintf("%s/thumbnails", output_final_folder), showWarnings = FALSE, recursive = TRUE)
# 4.8 Save all features inside the input folder
bandnames <- c(paste0("B",1:8), "B8A", paste0("B", 9:12), "CDI", "VV", "VH", "angle", "elevation", "landuse", "cloudshadow_direction")
input_data <- raster::stack(
final_stack[[1:13]]/10000, final_stack[[14]], final_stack[[15:17]], final_stack[[22:23]], final_stack[[25]]
)
final_stack
bandnames
final_stack
# 4.8 Save all features inside the input folder
colnames(final_stack)
# 4.8 Save all features inside the input folder
names(final_stack)
# 4.8 Save all features inside the input folder
bandnames <- c(paste0("B",1:8), "B8A", paste0("B", 9:12), "CDI", "VV", "VH", "angle", "elevation", "landuse", "cloudshadow_direction")
bandnames
bandnames
IPL_multitemporal_cloud_logical
IPL_multitemporal_cloud_logical
bandnames <- c(paste0("B",1:8), "B8A", paste0("B", 9:12), "CDI", "VV", "VH", "angle", "elevation", "landuse", "cloudshadow_direction")
# 4.8 Save all features inside the input folder
bandnames <- c(paste0("B",1:8), "B8A", paste0("B", 9:12), "CDI", "VV", "VH", "angle", "elevation", "landuse", "cloudshadow_direction")
input_data <- raster::stack(
final_stack[[1:13]]/10000, final_stack[[14]], final_stack[[15:17]], final_stack[[22:23]], final_stack[[24]]
)
names(input_data)
# 4.8 Save all features inside the input folder
bandnames <- c(paste0("B",1:8), "B8A", paste0("B", 9:12), "CDI", "VV", "VH", "angle", "elevation", "landuse", "cloudshadow_direction")
if (IPL_multitemporal_cloud_logical) {
input_data <- raster::stack(
final_stack[[1:13]]/10000, final_stack[[14]], final_stack[[15:17]], final_stack[[22:23]], final_stack[[24]]
)
} else {
input_data <- raster::stack(
final_stack[[1:13]]/10000, final_stack[[14]], final_stack[[15:17]], final_stack[[22:23]], final_stack[[25]]
)
}
IPL_multitemporal_cloud_logical
# 4.8 Save all features inside the input folder
bandnames <- c(paste0("B",1:8), "B8A", paste0("B", 9:12), "CDI", "VV", "VH", "angle", "elevation", "landuse", "cloudshadow_direction")
if (!IPL_multitemporal_cloud_logical) {
input_data <- raster::stack(
final_stack[[1:13]]/10000, final_stack[[14]], final_stack[[15:17]], final_stack[[22:23]], final_stack[[24]]
)
} else {
input_data <- raster::stack(
final_stack[[1:13]]/10000, final_stack[[14]], final_stack[[15:17]], final_stack[[22:23]], final_stack[[25]]
)
}
input_spec <- sprintf("%s/input/%s.tif", output_final_folder, bandnames)
lapply(1:20, function(x) writeRaster(input_data[[x]], input_spec[x], overwrite = TRUE))
# 4.9 Save all cloud mask inside the target folder
# 18-19 -> cmask_s2cloudness| cmask_s2cloudness_reclass (0,1)
# 20-21 -> cmask_sen2cor | cmask_sen2cor_reclass (0,1,2)
# 25 -> IPL_cloudmask_reclass
bandnames <- c("s2cloudness_prob", "s2cloudness_reclass", "sen2cor_real",
"sen2cor_reclass", "IPL_cloudmask_reclass")
bandnames <- c("s2cloudness_prob", "s2cloudness_reclass", "sen2cor_real",
"sen2cor_reclass", "IPL_cloudmask_reclass")
IPL_cloudmask_reclass <- final_stack[[24]]
final_stack[[24]]
IPL_multitemporal_cloud_logical
!IPL_multitemporal_cloud_logical
IPL_multitemporal_cloud_logical
IPL_cloudmask_reclass <- final_stack[[24]]
# 4.10 Save cloud labels
benchmarch_data <- stack(final_stack[[c(18:21)]], IPL_cloudmask_reclass)
target_spec <- sprintf("%s/target/%s.tif", output_final_folder, bandnames)
lapply(1:5, function(x) writeRaster(benchmarch_data[[x]], target_spec[x], overwrite = TRUE))
benchmarch_data
benchmarch_data
benchmarch_data <- stack(final_stack[[c(18:21)]])
benchmarch_data
target_spec <- sprintf("%s/target/%s.tif", output_final_folder, bandnames)
benchmarch_data
final_stack[[25]]
final_stack[[24]]
cloudshadow_dir <- final_stack[[24]]
cloudshadow_dir
mean(cloudshadow_dir)
mean(getValues(cloudshadow_dir))
mean(getValues(cloudshadow_dir))
mean(getValues(cloudshadow_dir))
mean(getValues(cloudshadow_dir)) < 0
cloudshadow_dir
cloudshadow_dir + 360
cloudshadow_dir
#' Function to create metadata  (i.e. metadata_1500.json)
#'
#' This function is used in select_dataset_thumbnail_creator to create the
#' final json file to be fill out for the labelers.
#'
#' @param jsonfile metadata (*.json) with the sentinel2 ID.
#' @param kernel_size Size of the kernel.
#' @param output_final Folder where to save the results.
#'
dataset_creator_chips <- function(jsonfile,
kernel_size = c(255, 255),
output_final = "cloudsen12/") {
point_name <- paste0("point_", gsub("[a-zA-Z]|_|\\.","", basename(jsonfile)))
# 1. Read JSON file
jsonfile_r <- jsonlite::read_json(jsonfile)
# 2. Identify all the S2 images
s2_idsposition <- which(sapply(strsplit(names(jsonfile_r), "_"), length) == 3)
s2_ids <- sprintf("COPERNICUS/S2/%s", names(jsonfile_r)[s2_idsposition])
# 3. Create a st_point representing the center of the tile (255x255)
st_point <- st_sfc(geometry = st_point(c(jsonfile_r$x, jsonfile_r$y)), crs = 4326)
crs_kernel <- ee$Image(s2_ids[1])$select(0)$projection()$getInfo()$crs
point_utm <- st_transform(st_point, crs_kernel)
ee_point <- ee$Geometry$Point(point_utm[[1]], proj = crs_kernel)
# 4. Download each image for the specified point
for (s2_id in s2_ids) {
message(sprintf("Downloading: %s", s2_id))
# 4.1 S2 ID and dates
s2_img <- ee$Image(s2_id)
s2_date <- ee_get_date_img(s2_img)[["time_start"]]
# 4.2 S1 ID
s1_id <- ee_get_s1(point = ee_point, s2_date = s2_date)
s1_img <- ee$Image(s1_id)
# 4.3 Create an Image collection with S2, S1 and cloud mask information
s2_s1_img <- ee_merge_s2_full(s2_id, s1_id, s2_date)
# 4.4 ipl_uv algorithm
IPL_multitemporal_cloud_logical <- ee_upl_cloud_logical(
sen2id = basename(s2_id),
roi =  s2_img$geometry()
)
if (IPL_multitemporal_cloud_logical) {
IPL_multitemporal_cloud <- ee_upl_cloud(
sen2id = basename(s2_id),
roi =  s2_img$geometry()
)
s2_s1_img <- s2_s1_img %>%
ee$Image$addBands(IPL_multitemporal_cloud) %>%
ee$Image$unmask(-999)
}
# 4.5 Add IPL algorithm and shadow direction
s2_fullinfo <- s2_s1_img %>%
ee$Image$addBands(shadow_direction(image = s2_img))
# 4.6 Create a 511x511 tile (list -> data_frame -> sp -> raster)
band_names <- c(s2_fullinfo$bandNames()$getInfo(), "x", "y")
s2_img_array <- s2_fullinfo$addBands(s1_img) %>%
ee$Image$addBands(ee$Image$pixelCoordinates(projection = crs_kernel)) %>%
ee$Image$neighborhoodToArray(
kernel = ee$Kernel$rectangle(kernel_size[1], kernel_size[2], "pixels")
) %>%
ee$Image$sampleRegions(ee$FeatureCollection(ee_point),
projection = crs_kernel,
scale = 10) %>%
ee$FeatureCollection$getInfo()
extract_fn <- function(x) as.numeric(unlist(s2_img_array$features[[1]]$properties[x]))
image_as_df <- do.call(cbind,lapply(band_names, extract_fn))
colnames(image_as_df) <- band_names
image_as_tibble <- as_tibble(image_as_df)
coordinates(image_as_tibble) <- ~x+y
sf_to_stack <- function(x) rasterFromXYZ(image_as_tibble[x])
final_stack <- stack(lapply(names(image_as_tibble), sf_to_stack))
crs(final_stack) <- st_crs(crs_kernel)$proj4string
# 4.7 Prepare folders for iris
output_final_d <- sprintf("%s/dataset", output_final)
output_final_folder <- sprintf("%s/dataset/%s/%s", output_final, point_name, basename(s2_id))
metadata_main <- sprintf("%s/cloud_segmentation_%s.json", output_final, point_name)
metadata_spec <- sprintf("%s/dataset/%s/%s/metadata.json", output_final, point_name, basename(s2_id))
dir.create(sprintf("%s/input", output_final_folder), showWarnings = FALSE, recursive = TRUE)
dir.create(sprintf("%s/target", output_final_folder), showWarnings = FALSE, recursive = TRUE)
dir.create(sprintf("%s/thumbnails", output_final_folder), showWarnings = FALSE, recursive = TRUE)
# 4.8 Save all features inside the input folder
bandnames <- c(paste0("B",1:8), "B8A", paste0("B", 9:12), "CDI", "VV", "VH", "angle", "elevation", "landuse", "cloudshadow_direction")
if (!IPL_multitemporal_cloud_logical) {
cloudshadow_dir <- final_stack[[24]]
if (mean(getValues(cloudshadow_dir)) < 0) {
cloudshadow_dir <- cloudshadow_dir + 360
}
input_data <- raster::stack(
final_stack[[1:13]]/10000, final_stack[[14]], final_stack[[15:17]], final_stack[[22:23]], cloudshadow_dir
)
} else {
cloudshadow_dir <- final_stack[[25]]
if (mean(getValues(cloudshadow_dir)) < 0) {
cloudshadow_dir <- cloudshadow_dir + 360
}
input_data <- raster::stack(
final_stack[[1:13]]/10000, final_stack[[14]], final_stack[[15:17]], final_stack[[22:23]], cloudshadow_dir
)
}
input_spec <- sprintf("%s/input/%s.tif", output_final_folder, bandnames)
lapply(1:20, function(x) writeRaster(input_data[[x]], input_spec[x], overwrite = TRUE))
# 4.9 Save all cloud mask inside the target folder
# 18-19 -> cmask_s2cloudness| cmask_s2cloudness_reclass (0,1)
# 20-21 -> cmask_sen2cor | cmask_sen2cor_reclass (0,1,2)
# 25 -> IPL_cloudmask_reclass
if (!IPL_multitemporal_cloud_logical) {
bandnames <- c("s2cloudness_prob", "s2cloudness_reclass", "sen2cor_real",
"sen2cor_reclass")
benchmarch_data <- stack(final_stack[[c(18:21)]])
target_spec <- sprintf("%s/target/%s.tif", output_final_folder, bandnames)
lapply(1:4, function(x) writeRaster(benchmarch_data[[x]], target_spec[x], overwrite = TRUE))
} else {
bandnames <- c("s2cloudness_prob", "s2cloudness_reclass", "sen2cor_real",
"sen2cor_reclass", "IPL_cloudmask_reclass")
IPL_cloudmask_reclass <- final_stack[[24]]
# 4.10 Save cloud labels
benchmarch_data <- stack(final_stack[[c(18:21)]], IPL_cloudmask_reclass)
target_spec <- sprintf("%s/target/%s.tif", output_final_folder, bandnames)
lapply(1:5, function(x) writeRaster(benchmarch_data[[x]], target_spec[x], overwrite = TRUE))
}
# 4.11 Create cloud-segmentation.json (main file in iris software)
ee_create_cloudseg(path = metadata_main)
# 4.12 Create metadata.json for each file
ee_create_metadata(
id = basename(s2_id),
point = c(jsonfile_r$y, jsonfile_r$x),
path = metadata_spec
)
}
# 5. Save geometry
roi <- extent(final_stack[[1]]) %>%
st_bbox() %>%
st_as_sfc()
st_crs(roi) <- crs_kernel
write_sf(roi, sprintf("%s/%s.gpkg", dirname(output_final_folder), point_name))
}
jsonfile_f <- search_metajson(pattern = jsonfile, clean = FALSE)
jsonfile_f
dataset_creator_chips(
jsonfile = jsonfile_f,
output_final = "/home/csaybar/Desktop/cloudsen12"
)
# 8. Validation
drive_jsonfile <- drive_ls(
path = as_id("1fBGAjZkjPEpPr0p7c-LtJmfbLq3s87RK")
)
set.seed(100)
tile_monitoring <- function() {
drive_jsonfile <- drive_ls(
path = as_id("1fBGAjZkjPEpPr0p7c-LtJmfbLq3s87RK")
)
see_changes_get_time <- function(x) drive_jsonfile[x,]$drive_resource[[1]]$createdTime
see_changes_get_author <- function(x) drive_jsonfile[x,]$drive_resource[[1]]$lastModifyingUser$displayName
author_img_selection <- sapply(1:nrow(drive_jsonfile), see_changes_get_author)
time_img_selection <- sapply(1:nrow(drive_jsonfile), see_changes_get_time)
remove_cesar <- !author_img_selection == "Cesar Luis Aybar"
author_img_selection <- author_img_selection[remove_cesar] %>%
strsplit(" ") %>%
sapply(function(x) x[[1]][[1]])
time_img_selection <- time_img_selection[remove_cesar] %>% as.POSIXct %>% as.character
img_sel_df <- data_frame(author = author_img_selection, date = as.Date(time_img_selection)) %>%
filter(date > as.Date("2021-02-12")) %>%
group_by(author) %>%
summarise(labels = length(author))
ggplot(img_sel_df, aes(x = author, y = labels)) +
geom_bar(stat="identity") +
theme_classic()
}
tile_monitoring()
set.seed(100)
jsonfiles <- drive_jsonfile$name[sample(length(drive_jsonfile$name), 20)]
for (jsonfile in jsonfiles) {
jsonfile_f <- search_metajson(pattern = jsonfile, clean = FALSE)
dataset_creator_chips(
jsonfile = jsonfile_f,
output_final = "/home/csaybar/Desktop/cloudsen12"
)
}
